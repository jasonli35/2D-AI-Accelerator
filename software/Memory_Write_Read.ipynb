{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b772596f-59fe-4a77-885b-3a64746d6edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n",
      "Test: [0/79]\tTime 0.538 (0.538)\tLoss 0.1848 (0.1848)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.130% \n"
     ]
    }
   ],
   "source": [
    "from utilities import Utilities\n",
    "from models import *\n",
    "from data_loader import testloader, trainloader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = VGG16_quant()\n",
    "model_name = \"VGG16_quant\"\n",
    "Utilities.test_model(model, model_name, testloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1378e-45f4-4ae3-b309-8db8b6318fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import Utilities\n",
    "weight_decay = 1e-4\n",
    "epochs = 20\n",
    "lr = 2e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "pre_best_prec = Utilities.train_model(model, model_name, optimizer, trainloader, criterion, epochs, testloader, pre_best_prec=pre_best_prec, reg_alpha=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "42 -th layer prehooked\n",
      "47 -th layer prehooked\n",
      "51 -th layer prehooked\n",
      "55 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_q = model.features[3].weight_q\n",
    "w_alpha = model.features[3].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "# print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = save_output.outputs[1][0]\n",
    "act_alpha  = model.features[3].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "# print(act_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "victorian-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conv_int = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = model.features[3].bias\n",
    "output_int = conv_int(act_int)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
    "# print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, padding=1)\n",
    "conv_ref.weight = model.features[3].weight_q\n",
    "conv_ref.bias = model.features[3].bias\n",
    "output_ref = conv_ref(act)\n",
    "#print(output_ref)\n",
    "\n",
    "# print(abs((output_ref - output_recovered)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subsequent-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# act_int.size = torch.Size([128, 64, 32, 32])  <- batch_size, input_ch, ni, nj\n",
    "a_int = act_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "                      \n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "ic_tileg = range(int(len(icg)/array_size))\n",
    "oc_tileg = range(int(len(ocg)/array_size))\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
    "# a_pad.size() = [64, 32+2pad, 32+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "# a_pad.size() = [64, (32+2pad)*(32+2pad)]\n",
    "\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tileg), array_size,    a_pad.size(1)).cuda() \n",
    "w_tile = torch.zeros(len(oc_tileg)*len(ic_tileg), array_size, array_size, len(kijg)).cuda() \n",
    "with torch.no_grad():\n",
    "    for ic_tile in ic_tileg:\n",
    "        a_tile[ic_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
    "with torch.no_grad():\n",
    "    for ic_tile in ic_tileg:\n",
    "        for oc_tile in oc_tileg:\n",
    "            w_tile[oc_tile*len(oc_tileg) + ic_tile,:,:,:] = w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, :]\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## psum nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda() \n",
    "with torch.no_grad():\n",
    "    for kij in kijg:\n",
    "        for ic_tile in ic_tileg:       # Tiling into array_sizeXarray_size array\n",
    "            for oc_tile in oc_tileg:   # Tiling into array_sizeXarray_size array        \n",
    "                for nij in p_nijg:       # time domain, sequentially given input\n",
    "                        m = nn.Linear(array_size, array_size, bias=False)\n",
    "                        #m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
    "                        m.weight = torch.nn.Parameter(w_tile[len(oc_tileg)*oc_tile+ic_tile,:,:,kij])\n",
    "                        psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,:,nij]).cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe53cc02-5356-4f8c-9c1a-29eb015a1c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0000,  2.0000, 15.0000,  0.0000, 14.0000, 13.0000, 12.0000, 15.0000],\n",
       "        [ 3.0000, 13.0000, 14.0000,  1.0000,  3.0000, -0.0000,  0.0000,  5.0000],\n",
       "        [15.0000, 14.0000,  0.0000, 15.0000, -0.0000, 15.0000, 14.0000, 14.0000],\n",
       "        [ 0.0000,  0.0000, 15.0000, 14.0000,  2.0000,  2.0000,  1.0000,  2.0000],\n",
       "        [ 2.0000,  4.0000, 14.0000, -0.0000,  1.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 1.0000,  4.0000,  0.0000, 15.0000, 15.0000,  2.0000,  1.0000, 14.0000],\n",
       "        [ 0.0000,  1.0000, 14.0000, 14.0000,  2.0000, 11.0000, -0.0000, 13.0000],\n",
       "        [ 3.0000,  2.0000, 12.0000,  1.0000, 15.0000, 11.0000,  1.0000, 14.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(array_size, array_size, bias=False)\n",
    "w_tile[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631e487a-25ea-4296-9fa8-b9b014d438dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0000, 4.0000, 0.0000, 0.0000, 1.0000, 3.0000, 4.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tile[0,:,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "with torch.no_grad():\n",
    "    for o_nij in o_nijg: \n",
    "        for kij in kijg:\n",
    "            for ic_tile in ic_tileg:    \n",
    "                for oc_tile in oc_tileg:   \n",
    "                    out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] = out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] + \\\n",
    "                    psum[ic_tile, oc_tile, :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 4th index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_2D = torch.reshape(out, (out.size(0), o_ni_dim, -1))\n",
    "difference = (out_2D - output_int[0,:,:,:])\n",
    "# print(difference.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "skilled-projector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "tile_id = 0 \n",
    "nij = 200 # just a random number\n",
    "X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('activation.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accomplished-folks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Complete this cell ###\n",
    "tile_id = 0 \n",
    "kij = 0\n",
    "W = w_tile[tile_id,:,:,kij]  # w_tile[tile_num, array col num, array row num, kij]\n",
    "\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('weight.txt', 'w') #write to file\n",
    "file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "for col in range(W.size(0)):\n",
    "    for row in range(W.size(1)-1, -1, -1):\n",
    "        weight = W[col,row]\n",
    "        if weight < 0:\n",
    "            weight += 16\n",
    "        file.write(int_to_fixed_binary_alt(int(weight), 4))\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "        \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45be7d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0111'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def int_to_fixed_binary_alt(number, width):\n",
    "    binary_representation = bin(number)[2:]  # Remove the '0b' prefix\n",
    "    return binary_representation.zfill(width)\n",
    "\n",
    "int_to_fixed_binary_alt(7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coastal-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  2., 15.,  0., 14., 13., 12., 15.], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:] # check this number with your 2nd line in weight.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stupid-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Complete this cell ###\n",
    "ic_tile_id = 0 \n",
    "oc_tile_id = 0 \n",
    "\n",
    "\n",
    "kij = 0\n",
    "nij = 200\n",
    "psum_tile = psum[ic_tile_id,oc_tile_id,:,nij:nij+64,kij]  \n",
    "\n",
    "# psum[len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)]\n",
    "\n",
    "        \n",
    "bit_precision = 16\n",
    "file = open('psum.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "neg_offset = 2**bit_precision\n",
    "\n",
    "for time in range(psum_tile.size(1)):\n",
    "    for col in range(psum_tile.size(0) - 1, -1, -1):\n",
    "        curr_psum = psum_tile[col,time]\n",
    "        if curr_psum < 0:\n",
    "            curr_psum += neg_offset\n",
    "        file.write(int_to_fixed_binary_alt(int(curr_psum), bit_precision))\n",
    "    file.write('\\n')\n",
    "file.close()        \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "psum_tile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-hundred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-drove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-institute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-taste",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-tribune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-complex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-procurement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
